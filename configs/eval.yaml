# Evaluation configuration for ABR Transformer
# This file configures the evaluation pipeline for both reconstruction and generation modes

# Dataset configuration
dataset:
  data_path: "data/processed/ultimate_dataset_with_clinical_thresholds.pkl"  # Path to dataset
  batch_size: 32
  num_workers: 4
  pin_memory: true
  return_peak_labels: true  # Enable peak labels for classification evaluation

# Model configuration
model:
  checkpoint_path: "checkpoints/enhanced/best.pth"
  device: "cuda"  # or "cpu"
  precision: "float32"  # or "float16"
  # Model architecture parameters
  input_channels: 1
  static_dim: 4
  sequence_length: 200
  d_model: 256
  n_layers: 6
  n_heads: 8
  ff_mult: 4
  dropout: 0.10
  use_timestep_cond: true
  use_static_film: true

# Evaluation configuration
evaluation:
  mode: "generation"  # "reconstruction" or "generation"
  num_samples: 1000  # Number of samples to evaluate
  seed: 42  # Random seed for reproducibility
  
  # Generation-specific settings
  generation:
    num_steps: 1000  # Number of diffusion steps
    guidance_scale: 1.0  # Classifier-free guidance scale
    temperature: 1.0  # Sampling temperature
    ddim_eta: 0.0  # DDIM eta parameter
  
  # Advanced evaluation settings
  advanced:
    reconstruction:
      timestep_strategy: "uniform"  # "fixed", "uniform", "random_subset"
      fixed_timestep: 500  # Used when timestep_strategy is "fixed"
    generation:
      cfg_scale: 1.0  # Classifier-free guidance scale
    max_samples: null  # Limit evaluation to specific number of samples

# Metrics configuration
metrics:
  # Signal quality metrics
  signal:
    mse: true
    correlation: true
    snr: true
    psnr: true
    ssim: true
    stft_loss: true
  
  # Peak classification metrics
  peak_classification:
    enabled: true  # Enable 5th peak classification evaluation
    threshold: 0.5  # Binary classification threshold (post-sigmoid)
    bootstrap_ci: 1000  # Number of bootstrap resamples for confidence intervals
    significance_tests: true  # Enable statistical significance testing
    clinical_validation: true  # Enable clinical validation metrics
  
  # Statistical analysis configuration
  statistical_analysis:
    confidence_level: 0.95  # Confidence interval level
    bootstrap_method: 'percentile'  # Options: 'percentile', 'bca', 'basic'
    multiple_testing_correction: 'bonferroni'  # Multiple comparison correction
    effect_size_metrics: ['cohens_d', 'cliff_delta']  # Effect size calculations
  
  # Clinical validation metrics
  clinical_metrics:
    sensitivity_analysis: true  # ROC analysis and optimal threshold finding
    specificity_targets: [0.8, 0.9, 0.95]  # Sensitivity at specific specificity levels
    prevalence_adjustment: true  # Adjust metrics based on dataset prevalence
    diagnostic_odds_ratio: true  # Clinical diagnostic metrics
  
  # Comparative analysis (disabled by default)
  comparative_analysis:
    enabled: false  # Enable when comparing multiple runs
    baseline_run: null  # Specify baseline comparison
    comparison_metrics: ['accuracy', 'f1', 'auroc', 'sensitivity', 'specificity']
    statistical_tests: ['paired_t_test', 'wilcoxon', 'mcnemar']  # For comparing paired samples

# Output configuration
output:
  save_dir: "evaluation_results"
  save_format: "json"  # "json" or "pickle"
  save_samples: false  # Save individual sample results
  save_plots: true  # Save evaluation plots

# Reporting configuration
report:
  save_classification_metrics: true  # Save detailed classification results
  save_roc_curves: true  # Save ROC curve data and plots
  save_pr_curves: true  # Save PR curve data and plots
  save_confusion_matrices: true  # Save confusion matrix visualizations
  publication_ready: true  # Generate high-quality publication figures
  include_confidence_intervals: true  # Include confidence intervals in reports
  statistical_annotations: true  # Add statistical significance annotations
  save_topk_examples: 10  # Number of best/worst examples to save
  save_spectrograms: false  # Enable spectrogram generation

# Visualization configuration
visualization:
  spectrogram_params: {}  # Parameters for spectrogram generation
  scatter_plots: true  # Enable scatter plot generation
  metrics_correlation: true  # Enable metrics correlation plots

# TensorBoard logging
tensorboard:
  enabled: true
  log_dir: "logs/evaluation"
  log_metrics: true
  log_plots: true
  log_samples: false

# Performance configuration
performance:
  use_amp: false  # Use automatic mixed precision
  benchmark: false  # Benchmark model performance
  profile: false  # Profile model execution
