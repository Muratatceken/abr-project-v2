{"step": 0, "epoch": 0, "timestamp": 1754368529.2667751, "loss_components": {"diffusion_loss": 2.7089786529541016, "total_loss": 2.7089786529541016}, "gradient_norm": 74.78461250247429, "learning_rate": 5e-05}
{"step": 0, "epoch": 0, "timestamp": 1754368531.7618098, "loss_components": {"diffusion_loss": 2.650526523590088, "total_loss": 2.650526523590088}, "gradient_norm": 104.56483101434023, "learning_rate": 5e-05}
{"step": 0, "epoch": 0, "timestamp": 1754368533.878352, "loss_components": {"diffusion_loss": 2.7665727138519287, "total_loss": 2.7665727138519287}, "gradient_norm": 131.36224065381364, "learning_rate": 5e-05}
{"step": 0, "epoch": 0, "timestamp": 1754368535.992039, "loss_components": {"diffusion_loss": 2.5842952728271484, "total_loss": 2.5842952728271484}, "gradient_norm": 145.19054142703524, "learning_rate": 5e-05}
{"step": 0, "epoch": 0, "timestamp": 1754368537.993582, "loss_components": {"diffusion_loss": 3.2232844829559326, "total_loss": 3.2232844829559326}, "gradient_norm": 190.62991289890618, "learning_rate": 5e-05}
{"step": 0, "epoch": 0, "timestamp": 1754368540.059349, "loss_components": {"diffusion_loss": 2.7053439617156982, "total_loss": 2.7053439617156982}, "gradient_norm": 202.34660201696985, "learning_rate": 5e-05}
{"step": 0, "epoch": 0, "timestamp": 1754368542.935572, "loss_components": {"diffusion_loss": 2.919039011001587, "total_loss": 2.919039011001587}, "gradient_norm": 279.55017139811196, "learning_rate": 5e-05}
{"step": 10, "epoch": 0, "timestamp": 1754368744.886705, "loss_components": {"diffusion_loss": 1.7742489576339722, "total_loss": 1.7742489576339722}, "gradient_norm": 0.0, "learning_rate": 5e-05}
{"step": 10, "epoch": 0, "timestamp": 1754368746.8090901, "loss_components": {"diffusion_loss": 1.9009071588516235, "total_loss": 1.9009071588516235}, "gradient_norm": 46.4153802292529, "learning_rate": 5e-05}
{"step": 10, "epoch": 0, "timestamp": 1754368748.8219242, "loss_components": {"diffusion_loss": 1.708024263381958, "total_loss": 1.708024263381958}, "gradient_norm": 58.857700257021996, "learning_rate": 5e-05}
{"step": 10, "epoch": 0, "timestamp": 1754368751.48612, "loss_components": {"diffusion_loss": 2.044447660446167, "total_loss": 2.044447660446167}, "gradient_norm": 89.30548279513484, "learning_rate": 5e-05}
{"step": 10, "epoch": 0, "timestamp": 1754368753.756686, "loss_components": {"diffusion_loss": 1.8242250680923462, "total_loss": 1.8242250680923462}, "gradient_norm": 99.92314371434188, "learning_rate": 5e-05}
{"step": 10, "epoch": 0, "timestamp": 1754368755.9718888, "loss_components": {"diffusion_loss": 1.6654448509216309, "total_loss": 1.6654448509216309}, "gradient_norm": 103.6890434820851, "learning_rate": 5e-05}
{"step": 10, "epoch": 0, "timestamp": 1754368758.135825, "loss_components": {"diffusion_loss": 1.8955316543579102, "total_loss": 1.8955316543579102}, "gradient_norm": 117.43490458586577, "learning_rate": 5e-05}
{"step": 10, "epoch": 0, "timestamp": 1754368760.3326888, "loss_components": {"diffusion_loss": 1.799072027206421, "total_loss": 1.799072027206421}, "gradient_norm": 123.1714667814861, "learning_rate": 5e-05}
{"step": 20, "epoch": 0, "timestamp": 1754368929.3636742, "loss_components": {"diffusion_loss": 1.7441514730453491, "total_loss": 1.7441514730453491}, "gradient_norm": 0.0, "learning_rate": 5e-05}
{"step": 20, "epoch": 0, "timestamp": 1754368931.528455, "loss_components": {"diffusion_loss": 1.5362929105758667, "total_loss": 1.5362929105758667}, "gradient_norm": 28.728821550527528, "learning_rate": 5e-05}
{"step": 20, "epoch": 0, "timestamp": 1754368933.522581, "loss_components": {"diffusion_loss": 1.5815820693969727, "total_loss": 1.5815820693969727}, "gradient_norm": 56.88791780289936, "learning_rate": 5e-05}
{"step": 20, "epoch": 0, "timestamp": 1754368935.5627189, "loss_components": {"diffusion_loss": 1.5249083042144775, "total_loss": 1.5249083042144775}, "gradient_norm": 64.28912933706349, "learning_rate": 5e-05}
{"step": 20, "epoch": 0, "timestamp": 1754368937.6628501, "loss_components": {"diffusion_loss": 1.584717869758606, "total_loss": 1.584717869758606}, "gradient_norm": 67.80021796586442, "learning_rate": 5e-05}
{"step": 20, "epoch": 0, "timestamp": 1754368939.66133, "loss_components": {"diffusion_loss": 1.419560194015503, "total_loss": 1.419560194015503}, "gradient_norm": 73.52008876905779, "learning_rate": 5e-05}
{"step": 20, "epoch": 0, "timestamp": 1754368941.704926, "loss_components": {"diffusion_loss": 1.5811058282852173, "total_loss": 1.5811058282852173}, "gradient_norm": 84.03262243978618, "learning_rate": 5e-05}
{"step": 20, "epoch": 0, "timestamp": 1754368943.724565, "loss_components": {"diffusion_loss": 1.5427297353744507, "total_loss": 1.5427297353744507}, "gradient_norm": 86.3830503432358, "learning_rate": 5e-05}
{"step": 30, "epoch": 0, "timestamp": 1754369112.9345438, "loss_components": {"diffusion_loss": 1.3415131568908691, "total_loss": 1.3415131568908691}, "gradient_norm": 0.0, "learning_rate": 5e-05}
{"step": 30, "epoch": 0, "timestamp": 1754369115.367119, "loss_components": {"diffusion_loss": 1.4679006338119507, "total_loss": 1.4679006338119507}, "gradient_norm": 27.095425871416253, "learning_rate": 5e-05}
{"step": 30, "epoch": 0, "timestamp": 1754369117.647941, "loss_components": {"diffusion_loss": 1.4608631134033203, "total_loss": 1.4608631134033203}, "gradient_norm": 32.66698730400223, "learning_rate": 5e-05}
{"step": 30, "epoch": 0, "timestamp": 1754369119.948735, "loss_components": {"diffusion_loss": 1.3558988571166992, "total_loss": 1.3558988571166992}, "gradient_norm": 41.26235261212068, "learning_rate": 5e-05}
{"step": 30, "epoch": 0, "timestamp": 1754369122.242555, "loss_components": {"diffusion_loss": 1.2929614782333374, "total_loss": 1.2929614782333374}, "gradient_norm": 44.714912554685235, "learning_rate": 5e-05}
{"step": 30, "epoch": 0, "timestamp": 1754369124.468364, "loss_components": {"diffusion_loss": 1.3788461685180664, "total_loss": 1.3788461685180664}, "gradient_norm": 46.039564309674226, "learning_rate": 5e-05}
{"step": 30, "epoch": 0, "timestamp": 1754369128.386972, "loss_components": {"diffusion_loss": 1.3921644687652588, "total_loss": 1.3921644687652588}, "gradient_norm": 54.6618902963256, "learning_rate": 5e-05}
{"step": 30, "epoch": 0, "timestamp": 1754369131.730905, "loss_components": {"diffusion_loss": 1.4672785997390747, "total_loss": 1.4672785997390747}, "gradient_norm": 57.86501334092014, "learning_rate": 5e-05}
