project:
  name: ABR_HierarchicalUNet_Optimized_v2
  description: Optimized Hierarchical U-Net with compatible attention configuration
  version: 2.1.0
  author: AI Assistant
  experiment_name: max_performance
data:
  dataset_path: data/processed/ultimate_dataset_with_clinical_thresholds.pkl
  signal_length: 200
  static_dim: 4
  n_classes: 5
  splits:
    train_ratio: 0.75
    val_ratio: 0.15
    test_ratio: 0.1
    random_seed: 42
  dataloader:
    batch_size: 48
    num_workers: 6
    pin_memory: true
    drop_last: true
    shuffle_train: true
    prefetch_factor: 3
    persistent_workers: true
model:
  type: hierarchical_unet
  architecture:
    signal_length: 200
    static_dim: 4
    base_channels: 96
    n_levels: 4
    n_classes: 5
    dropout: 0.15
    encoder:
      n_s4_layers: 3
      d_state: 96
      use_enhanced_s4: true
    decoder:
      n_transformer_layers: 3
      n_heads: 12
      use_multi_scale_attention: true
      use_cross_attention: true
    film:
      hidden_dim: 96
      dropout: 0.15
    outputs:
      signal_activation: tanh
      peak_head_dim: 288
      class_head_dim: 288
      threshold_head_dim: 288
      use_attention_heads: true
      predict_uncertainty: true
diffusion:
  noise_schedule:
    type: cosine
    num_timesteps: 1000
    peak_preserve_ratio: 0.4
    beta_start: 0.0001
    beta_end: 0.02
  sampling:
    type: ddpm
    ddim_eta: 0.0
    num_sampling_steps: 100
    temperature: 0.9
    clip_denoised: true
    constraints:
      apply_constraints: true
      peak_latency_range:
      - 0.8
      - 8.5
      amplitude_range:
      - -0.6
      - 0.6
      smooth_kernel_size: 3
training:
  optimizer:
    type: adamw
    learning_rate: 0.0002
    weight_decay: 0.0001
    betas:
    - 0.9
    - 0.95
    eps: 1.0e-08
    amsgrad: false
  scheduler:
    type: cosine_annealing_warm_restarts
    T_0: 30
    T_mult: 2
    eta_min: 5.0e-07
    warmup_epochs: 5
    warmup_type: linear
  epochs: 300
  gradient_clip: 0.5
  accumulation_steps: 2
  log_frequency: 25
  validation:
    frequency: 1
    compute_metrics: true
    save_predictions: true
  checkpointing:
    save_frequency: 5
    save_best: true
    save_last: true
    save_top_k: 3
    save_dir: checkpoints
    monitor_metric: val_total_loss
  early_stopping:
    patience: 50
    min_delta: 1.0e-05
    monitor: val_total_loss
    mode: min
    restore_best_weights: true
loss:
  type: abr_diffusion
  weights:
    diffusion: 1.0
    peak_exist: 0.8
    peak_latency: 1.2
    peak_amplitude: 1.2
    classification: 1.5
    threshold: 1.0
  peak_loss_type: smooth_l1
  huber_delta: 0.5
  class_weights: balanced
  focal_loss:
    use_focal: true
    alpha: 0.75
    gamma: 2.5
  perceptual:
    use_perceptual: true
    feature_weights:
      peak_preservation: 3.0
      morphology: 1.5
      spectral: 1.0
      temporal: 2.0
evaluation:
  metrics:
    signal_metrics:
    - mse
    - mae
    - correlation
    - dtw_distance
    - snr
    - spectral_distance
    peak_metrics:
    - peak_mae
    - peak_accuracy
    - existence_f1
    - peak_correlation
    - timing_accuracy
    classification_metrics:
    - accuracy
    - f1_macro
    - f1_weighted
    - confusion_matrix
    - precision
    - recall
    threshold_metrics:
    - threshold_mae
    - threshold_r2
    - threshold_correlation
    - clinical_accuracy
  visualization:
    save_plots: true
    plot_types:
    - reconstruction
    - peaks
    - latent_space
    - generation_samples
    - loss_curves
    - attention_maps
    n_samples_plot: 20
    save_animations: true
  output_dir: outputs/evaluation
  save_detailed_results: true
  save_predictions: true
  save_embeddings: true
inference:
  generation:
    num_samples: 200
    batch_size: 24
    temperature: 0.9
    guidance_scale: 1.2
    use_cfg: true
  conditioning:
    age_range:
    - 18
    - 85
    intensity_range:
    - 55
    - 105
    rate_range:
    - 8
    - 85
    fmp_range:
    - 0.4
    - 1.0
  output_dir: outputs/inference
  save_formats:
  - signals
  - peaks
  - predictions
  - metadata
  - embeddings
  save_statistics: true
logging:
  level: INFO
  log_dir: logs
  use_tensorboard: true
  use_wandb: true
  wandb:
    project: abr-hierarchical-unet-optimized-v2
    entity: null
    tags:
    - diffusion
    - abr
    - s4
    - transformer
    - optimized
    - multi-task
    - v2
    - fixed
    group: production-v2
    notes: Optimized configuration v2 with fixed attention compatibility
reproducibility:
  seed: 42
  deterministic: true
  benchmark: false
hardware:
  device: cuda
  gpu_id: 0
  mixed_precision: true
  compile_model: true
  channels_last: true
paths:
  data_dir: data
  model_dir: models
  checkpoint_dir: /content/checkpoints/max_performance
  output_dir: /content/outputs/max_performance
  log_dir: /content/logs/max_performance
optimization:
  augmentation:
    enabled: true
    noise_std: 0.01
    time_stretch: 0.05
    amplitude_scale: 0.1
  model_optimization:
    use_flash_attention: false
    use_gradient_checkpointing: true
    use_weight_norm: false
  training_optimization:
    find_unused_parameters: false
    use_automatic_optimization: true
    precision: 16
